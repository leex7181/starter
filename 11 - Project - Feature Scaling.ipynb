{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c877c9",
   "metadata": {},
   "source": [
    "# Project - Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26869a35",
   "metadata": {},
   "source": [
    "![Data Science Workflow](img/ds-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc443c2",
   "metadata": {},
   "source": [
    "## Goal of Project\n",
    "- A sport magazine is writing an article on soccer players\n",
    "- They have a special interest in left-footed players\n",
    "- A question is whether they playing style can predict if a player is left-footed\n",
    "- The questions they want to answer:\n",
    "    - Can you from a features set on players predict if it is left-footed player\n",
    "    - If so, what features matters the most"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f362c4",
   "metadata": {},
   "source": [
    "## Step 1: Acquire\n",
    "- Explore problem\n",
    "- Identify data\n",
    "- Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cbbcb",
   "metadata": {},
   "source": [
    "### Step 1.a: Import libraries\n",
    "- Execute the cell below (SHIFT + ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0670a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9a799",
   "metadata": {},
   "source": [
    "### Step 1.b: Read the data\n",
    "- Use ```pd.read_parquet()``` to read the file `files/soccer.parquet`\n",
    "    - The data is from [Kaggle European Soccer Database](https://www.kaggle.com/hugomathien/soccer)\n",
    "- NOTE: Remember to assign the result to a variable (e.g., ```data```)\n",
    "- Apply ```.head()``` on the data to see all is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2a0e7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/leebyunghun/Documents/GitHub/starter/11 - Project - Feature Scaling.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leebyunghun/Documents/GitHub/starter/11%20-%20Project%20-%20Feature%20Scaling.ipynb#ch0000007?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39mfiles/soccer.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=432'>433</a>\u001b[0m \u001b[39m@doc\u001b[39m(storage_options\u001b[39m=\u001b[39mgeneric\u001b[39m.\u001b[39m_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=433'>434</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_parquet\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=434'>435</a>\u001b[0m     path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=439'>440</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=440'>441</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=441'>442</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=442'>443</a>\u001b[0m \u001b[39m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=443'>444</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=490'>491</a>\u001b[0m \u001b[39m    DataFrame\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=491'>492</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=492'>493</a>\u001b[0m     impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=494'>495</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=495'>496</a>\u001b[0m         path,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=496'>497</a>\u001b[0m         columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=499'>500</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=500'>501</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py:53\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=49'>50</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=50'>51</a>\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[0;32m---> <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=52'>53</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=53'>54</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=54'>55</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=55'>56</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=56'>57</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=57'>58</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=58'>59</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=59'>60</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=60'>61</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('files/soccer.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6f5b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3bec949d",
   "metadata": {},
   "source": [
    "## Step 2: Prepare\n",
    "- Explore data\n",
    "- Visualize ideas\n",
    "- Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5d948d",
   "metadata": {},
   "source": [
    "### Step 2.a: Check the data types\n",
    "- This step tells you if some numeric column is not represented numeric.\n",
    "- Apply `info()` to get an idea of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2803901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2867789a",
   "metadata": {},
   "source": [
    "### Step 2.b: Check for null (missing) values\n",
    "- Data often is missing entries - there can be many reasons for this\n",
    "- We need to deal with that (will do later in course)\n",
    "- Use ```.isnull().any()``` and `.isnull().sum()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0e875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d27dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "137fdfde",
   "metadata": {},
   "source": [
    "### Step 2.c: Drop missing data\n",
    "- A great idea is to investigate missing data and outliers\n",
    "- But for this project we ignore it\n",
    "- Apply `dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eaca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "599e5352",
   "metadata": {},
   "source": [
    "### Step 2.d: Limite dataset size\n",
    "- This project is only for demonstration\n",
    "- Limit the dataset to the first 2000 rows\n",
    "    - HINT: `iloc[:2000]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7d8519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cc1cabe",
   "metadata": {},
   "source": [
    "## Step 3: Analyze\n",
    "- Feature selection\n",
    "- Model selection\n",
    "- Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6600abc1",
   "metadata": {},
   "source": [
    "### Step 3.a: Feature Selection\n",
    "- The classifier we want to predict is `preferred_foot` (independent feature/classification)\n",
    "- For now we keep the other numeric features as depdent features\n",
    "    - HINT: Use `.info()` to see numeric columns\n",
    "    - HINT: Use `.drop([...], axis=1)`\n",
    "- Assign the dependent features to `X` and the independent feature to `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6eedc59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df916f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c1b5fc0",
   "metadata": {},
   "source": [
    "### Step 3.b: Split into train and test\n",
    "- Use `train_test_split` to divide into train and test data.\n",
    "- A great thing is to use `random_state` to be able to reproduce while experimenting\n",
    "```Python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456a2933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10fb4b4c",
   "metadata": {},
   "source": [
    "### Step 3.c: Normalize data\n",
    "- Create a `MinMaxScaler()`\n",
    "- Fit it on the `X_train` dataset\n",
    "- Then transform `X_train` and `X_test`\n",
    "- Remember to assign the results to unique variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d3492a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae1c0e31",
   "metadata": {},
   "source": [
    "### Step 3.c: Standardize data\n",
    "- Create a `StandardScaler()`\n",
    "- Fit it on the `X_train` dataset\n",
    "- Then transform `X_train` and `X_test`\n",
    "- Remember to assign the results to unique variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c37ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b36b02f4",
   "metadata": {},
   "source": [
    "### Step 3.d: Compare sets\n",
    "- For the Original, Normalized, and Standardized datasets\n",
    "    - Create a `SVM` model and fit it\n",
    "    - Predict values to calculate an accuracy score\n",
    "- HINT: For each dataset be inspired by this\n",
    "```Python\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6345e7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5fafc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e28dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9308daea",
   "metadata": {},
   "source": [
    "### Step 3.e: Finding most important feature\n",
    "- We now know that the features can predict if a player is left-footed\n",
    "- Now we need to find the most important features\n",
    "- [`permutation_importance`](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.permutation_importance.html) Permutation importance for feature evaluation.\n",
    "- We will use the standardized data and fit a new `SVC` model\n",
    "- Then use the `permutation_importance` to calculate it.\n",
    "```Python\n",
    "perm_importance = permutation_importance(svc, X_test_stand, y_test)\n",
    "```\n",
    "- The results will be found in `perm_importance.importances_mean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9716eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f2f8ce9",
   "metadata": {},
   "source": [
    "### Step 3.f: Visualize the results\n",
    "- To visualize the result we want the most important features sorted\n",
    "- This can be `perm_importance.importances_mean.argsort()`\n",
    "    - HINT: assign it to `sorted_idx`\n",
    "- Then to visualize it we will create a DataFrame\n",
    "```Python\n",
    "pd.DataFrame(perm_importance.importances_mean[sorted_idx], X_test.columns[sorted_idx], columns=['Value'])\n",
    "```\n",
    "- Then make a `barh` plot (use `figsize`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36dcba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98a71ee2",
   "metadata": {},
   "source": [
    "## Step 4: Report\n",
    "- Present findings\n",
    "- Visualize results\n",
    "- Credibility counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53c2de",
   "metadata": {},
   "source": [
    "### Step 4.a: Present findings\n",
    "- There are many ways to present the findings.\n",
    "- Be creative\n",
    "- Ideas\n",
    "    - Explore how the features are related to the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ed39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65201e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c865f1",
   "metadata": {},
   "source": [
    "## Step 5: Actions\n",
    "- Use insights\n",
    "- Measure impact\n",
    "- Main goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52b3d89",
   "metadata": {},
   "source": [
    "### Step 5.a: Reflection\n",
    "- There might not be any actions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18215cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a2e98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
