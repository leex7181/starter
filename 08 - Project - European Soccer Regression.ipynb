{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39c877c9",
   "metadata": {},
   "source": [
    "# Predict Soccer Players with Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26869a35",
   "metadata": {},
   "source": [
    "![Data Science Workflow](img/ds-workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06eeb79",
   "metadata": {},
   "source": [
    "## Goal of Project\n",
    "- Make a model to predict players overall rating based on metrics\n",
    "- This is a subset of the Kaggle dataset [European Soccer Database](https://www.kaggle.com/hugomathien/soccer)\n",
    "    - A bigger project is to predict outcomes of games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f362c4",
   "metadata": {},
   "source": [
    "## Step 1: Acquire\n",
    "- Explore problem\n",
    "- Identify data\n",
    "- Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8cbbcb",
   "metadata": {},
   "source": [
    "### Step 1.a: Import libraries\n",
    "- Execute the cell below (SHIFT + ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd471b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f9a799",
   "metadata": {},
   "source": [
    "### Step 1.b: Read the data\n",
    "- Use ```pd.read_parquet()``` to read the file `files/soccer.parquet`\n",
    "- NOTE: Remember to assign the result to a variable (e.g., ```data```)\n",
    "- Apply ```.head()``` on the data to see all is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abd8554d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/leebyunghun/Documents/GitHub/starter/08 - Project - European Soccer Regression.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/leebyunghun/Documents/GitHub/starter/08%20-%20Project%20-%20European%20Soccer%20Regression.ipynb#ch0000007?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_parquet(\u001b[39m'\u001b[39;49m\u001b[39mfiles/soccer.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/leebyunghun/Documents/GitHub/starter/08%20-%20Project%20-%20European%20Soccer%20Regression.ipynb#ch0000007?line=1'>2</a>\u001b[0m data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py:493\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=432'>433</a>\u001b[0m \u001b[39m@doc\u001b[39m(storage_options\u001b[39m=\u001b[39mgeneric\u001b[39m.\u001b[39m_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mstorage_options\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=433'>434</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_parquet\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=434'>435</a>\u001b[0m     path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=439'>440</a>\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=440'>441</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=441'>442</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=442'>443</a>\u001b[0m \u001b[39m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=443'>444</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=490'>491</a>\u001b[0m \u001b[39m    DataFrame\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=491'>492</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=492'>493</a>\u001b[0m     impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=494'>495</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m impl\u001b[39m.\u001b[39mread(\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=495'>496</a>\u001b[0m         path,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=496'>497</a>\u001b[0m         columns\u001b[39m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=499'>500</a>\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=500'>501</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py:53\u001b[0m, in \u001b[0;36mget_engine\u001b[0;34m(engine)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=49'>50</a>\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=50'>51</a>\u001b[0m             error_msgs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(err)\n\u001b[0;32m---> <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=52'>53</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=53'>54</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to find a usable engine; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=54'>55</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtried using: \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mfastparquet\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=55'>56</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA suitable version of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=56'>57</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpyarrow or fastparquet is required for parquet \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=57'>58</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msupport.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=58'>59</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTrying to import the above resulted in these errors:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=59'>60</a>\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00merror_msgs\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=60'>61</a>\u001b[0m     )\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=62'>63</a>\u001b[0m \u001b[39mif\u001b[39;00m engine \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpyarrow\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='file:///Users/leebyunghun/opt/anaconda3/lib/python3.8/site-packages/pandas/io/parquet.py?line=63'>64</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m PyArrowImpl()\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to find a usable engine; tried using: 'pyarrow', 'fastparquet'.\nA suitable version of pyarrow or fastparquet is required for parquet support.\nTrying to import the above resulted in these errors:\n - Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.\n - Missing optional dependency 'fastparquet'. fastparquet is required for parquet support. Use pip or conda to install fastparquet."
     ]
    }
   ],
   "source": [
    "data = pd.read_parquet('files/soccer.parquet')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db22e284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11862c2e",
   "metadata": {},
   "source": [
    "### Step 1.c: Data size\n",
    "- HINT: `len(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bec949d",
   "metadata": {},
   "source": [
    "## Step 2: Prepare\n",
    "- Explore data\n",
    "- Visualize ideas\n",
    "- Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2377dd7",
   "metadata": {},
   "source": [
    "### Step 2.a: Inspect the data\n",
    "- There are many metrics\n",
    "- To keep it simple let's keep the numeric\n",
    "    - HINT: find them with `.dtypes`\n",
    "- You can select all columns of numeric data types as follows `.select_dtypes(include='number')`\n",
    "    - HINT: assign all the numeric columns to your variable (this is needed for the model, as it does not understand non-numeric features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e6b2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670532d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include='number')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2867789a",
   "metadata": {},
   "source": [
    "### Step 2.b: Check for null (missing) values\n",
    "- Data often is missing entries - there can be many reasons for this\n",
    "- We need to deal with that (will do later in course)\n",
    "- Use ```.isnull().any()```\n",
    "- See how many have null values (Assuming `data` contains your data)\n",
    "```Python\n",
    "data.isnull().sum()/len(data)*100\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a6535d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8eb876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()/len(data)*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c7dd7b",
   "metadata": {},
   "source": [
    "### Step 2.c: Drop missing data\n",
    "- Remove rows with missing data\n",
    "- HINT: `.dropna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd8d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3a6b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data), len(data.dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137fdfde",
   "metadata": {},
   "source": [
    "### Step 2.d: Visualize data\n",
    "- Make a histogram of the `overall_rating`\n",
    "- This gives you an understanding of the data\n",
    "- What does it tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe6402b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overall_rating'].plot.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0d64c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['overall_rating'].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc1cabe",
   "metadata": {},
   "source": [
    "## Step 3: Analyze\n",
    "- Feature selection\n",
    "- Model selection\n",
    "- Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c050b4",
   "metadata": {},
   "source": [
    "### Step 3.a: Feature and target selection\n",
    "- The target data is given by `overall_rating`\n",
    "- As we do not have a description of the date, let's learn a bit about it\n",
    "    - HINT: Use `data.corr()['overall_rating'].sort_values(ascending=False)`\n",
    "- For simplicity de-select features you do not thing should be part of the analysis\n",
    "- Create DataFrames `X` and `y` containing the features and target, respectively.\n",
    "    - HINT: To get all columns except one use `.drop(['overall_rating', <insert other here>], axis=1)`\n",
    "    - HINT: Keep `y` as a DataFrame for simplicity later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd76ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()['overall_rating'].sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75fe7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select_dtypes(include='number')\n",
    "X = data.drop(['overall_rating', 'potential'], axis=1)\n",
    "y = data['overall_rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9420902d",
   "metadata": {},
   "source": [
    "### Step 3.b: Divide into test and train\n",
    "- We do this to test the accuracy of our model\n",
    "- The idea is: We train on one dataset, then test on another to see how it performs\n",
    "- To split dataset use\n",
    "```Python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "```\n",
    "- The `random_state=42` is used for reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f42cc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908a00b9",
   "metadata": {},
   "source": [
    "### Step 3.c: Train the model\n",
    "- Create a Linear Regression instance and fit it.\n",
    "- HINT: Do this on train data (`X_train` and `y_train`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4560f083",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfea57",
   "metadata": {},
   "source": [
    "### Step 3.d: Predict on test data\n",
    "- Here we make predictions\n",
    "- HINT: Use your model to predict `.predict(X_test)` and assign the result to `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lin.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd9a42",
   "metadata": {},
   "source": [
    "### Step 3.e: Evaluate the model\n",
    "- Apply r-squared on the predicted results and the real results\n",
    "- HINT: Use `r2_score` on `y_pred` and `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61173a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a71ee2",
   "metadata": {},
   "source": [
    "## Step 4: Report\n",
    "- Present findings\n",
    "- Visualize results\n",
    "- Credibility counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c842708",
   "metadata": {},
   "source": [
    "### Step 4.a: Present finding\n",
    "- This is more a practice of creating a model\n",
    "- But feel free to be creative\n",
    "- An option could be to investigate the best indicator of a player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28af5a75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff67d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65c865f1",
   "metadata": {},
   "source": [
    "## Step 5: Actions\n",
    "- Use insights\n",
    "- Measure impact\n",
    "- Main goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fef5c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9600a64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
